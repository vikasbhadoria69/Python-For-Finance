{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "import pickle\n",
    "import pandas_datareader.data as web\n",
    "import os\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikasbhadoria\\Desktop\\ML_Project1\\Python_for_finance\\dfs-stocks\n"
     ]
    }
   ],
   "source": [
    "cd dfs-stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using requests to get the data from web and the using beautifulsoup to make it more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp500_companies():\n",
    "    resp = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "    soup = bs.BeautifulSoup(resp.text)\n",
    "    table = soup.find(\"table\",{\"class\":\"wikitable sortable\"})\n",
    "    tickers = []\n",
    "    for row in table.findAll(\"tr\")[1:20]:\n",
    "        ticker = row.findAll(\"td\")[0].text\n",
    "        ticker = ticker[:-1]\n",
    "        tickers.append(ticker)\n",
    "    \n",
    "    with open(\"sp20_companies.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "      \n",
    "    print(tickers)\n",
    "    \n",
    "    return tickers\n",
    "#sp500_companies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data from yahoo and storing it in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = sp500_companies()\n",
    "    else:\n",
    "        with open(\"sp20_companies.pickle\",\"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "            \n",
    "    if not os.path.exists(\"dfs-stocks\"):\n",
    "        os.makedirs(\"dfs-stocks\")\n",
    "    \n",
    "    start = dt.datetime(2000,1,1)\n",
    "    end = dt.datetime(2016,12,31)\n",
    "    \n",
    "    for ticker in tickers[:]:\n",
    "        if not os.path.exists(\"{}.csv\".format(ticker)):\n",
    "            df = web.DataReader(ticker,\"yahoo\",start,end)\n",
    "            df.to_csv(\"{}.csv\".format(ticker))\n",
    "        else:\n",
    "            print(\"Already have {}\".format(ticker))\n",
    "            \n",
    "#get_data_from_yahoo()             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider only Adj Close of all companies and then combining all the data into one csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data():\n",
    "    with open(\"sp20_companies.pickle\",\"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "        \n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    for count,ticker in enumerate(tickers):\n",
    "        df = pd.read_csv(\"{}.csv\".format(ticker))\n",
    "        df.set_index(\"Date\",inplace=True)\n",
    "        df.rename(columns = {\"Adj Close\":ticker},inplace=True)\n",
    "        df.drop([\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"],1,inplace=True)\n",
    "        \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df,how=\"outer\")\n",
    "        \n",
    "        if count % 2 == 0:\n",
    "            print(count)\n",
    "    print(main_df.head())\n",
    "    main_df.to_csv(\"sp20_combined.csv\")\n",
    "\n",
    "#compile_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualisation and corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport matplotlib.pyplot as plt'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e2dc8bf9e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_visualize():\n",
    "    data = pd.read_csv(\"sp20_combined.csv\")\n",
    "    #print(data.head())\n",
    "    corr_matrix = data.corr()\n",
    "    plt.figure(figsize=(14,10))\n",
    "    return sns.heatmap(corr_matrix,cmap=\"YlGnBu\",linewidths=.5,annot=True)\n",
    "data_visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating labels for data based on weather to buy stock of a particular company or sell or hold. This depends on the %change in data from last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_labels(ticker):\n",
    "    hm_days = 7\n",
    "    data = pd.read_csv(\"sp20_combined.csv\",index_col=0)\n",
    "    tickers = data.columns.values.tolist()\n",
    "    data.fillna(0,inplace=True)\n",
    "    \n",
    "    for i in range(1,hm_days+1):\n",
    "        print(i)\n",
    "        data[\"{}_{}d\".format(ticker,i)] = (data[ticker].shift(-i)-data[ticker])/data[ticker]\n",
    "    data.fillna(0,inplace=True)\n",
    "    return tickers,data\n",
    "#process_data_for_labels(\"AMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_sell_hold(*args):\n",
    "    cols = [c for c in args]\n",
    "    requirement = 0.02\n",
    "    for col in cols:\n",
    "        if col > 0.018:\n",
    "            return 1\n",
    "        if col < -0.019:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(ticker):\n",
    "    tickers,data = process_data_for_labels(ticker)\n",
    "    \n",
    "    data[\"{}_target\".format(ticker)] = list(map(buy_sell_hold,data[\"{}_1d\".format(ticker)],\n",
    "                                             data[\"{}_2d\".format(ticker)],\n",
    "                                             data[\"{}_3d\".format(ticker)],\n",
    "                                             data[\"{}_4d\".format(ticker)],\n",
    "                                             data[\"{}_5d\".format(ticker)],\n",
    "                                             data[\"{}_6d\".format(ticker)],\n",
    "                                             data[\"{}_7d\".format(ticker)]))\n",
    "    vals= data[\"{}_target\".format(ticker)].values.tolist()\n",
    "    str_values = [str(i) for i in vals]\n",
    "    print(\"data_spread:\" , Counter(str_values))\n",
    "    data.fillna(0,inplace=True)\n",
    "    data = data.replace([np.inf,-np.inf],np.nan)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    data_vals = data[[ticker for ticker in tickers]].pct_change()\n",
    "    data_vals = data_vals.replace([np.inf,-np.inf],0)\n",
    "    data_vals.fillna(0,inplace=True)\n",
    "    \n",
    "    X = data_vals.values\n",
    "    y = data[\"{}_target\".format(ticker)].values\n",
    "    \n",
    "    return X,y,data\n",
    "#extract_features(\"ABT\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "data_spread: Counter({'1': 1802, '-1': 1374, '0': 1101})\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.40373831775700936\n",
      "prediction spread:  Counter({1: 726, -1: 220, 0: 124})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40373831775700936"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_ml(ticker):\n",
    "    X,y,data = extract_features(ticker)\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\n",
    "    \n",
    "    clf = VotingClassifier([\n",
    "        (\"lsvc\",svm.LinearSVC()),\n",
    "        (\"knn\",KNeighborsClassifier()),\n",
    "        (\"rfor\",RandomForestClassifier())])\n",
    "    clf.fit(X_train,y_train)\n",
    "    confidence = clf.score(X_test,y_test)\n",
    "    print(\"Accuracy: \",confidence )\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(\"prediction spread: \",Counter(predictions))\n",
    "    \n",
    "    return confidence\n",
    "\n",
    "do_ml(\"MMM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
